# Проект 6. Рекомендация тарифов

### Вводная: 
После успешного создания модели предсказания тарифов у вас появляется свободное время на улучшение своих навыков. По совету своих коллег вы решаете принять участие в соревновании на kaggle.com. Выбор падает на кейс по предсказанию ухода клиентов из крупного европейского банка. 
    
Основная задача: определить, останется ли клиент в банке или же разорвёт контракт. Для этого вам предоставлены обезличенные данные о клиентах и их поведении.

Скоринг в этом соревновании производится F1-мерой, поэтому нужно попытаться получить её как можно выше. Чтобы попасть на лидерборд F1-score должен быть больше 0.59. Тестирование модели необходимо проводить самостоятельно на открытых данных.
    
Также, поскольку решается реальный кейс, банк попросил измерять и *AUC-ROC*. 
     
Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)


### Цель проекта 
Построить модель, которая спрогнозирует уход клиента из банка. Её F1-score должен быть больше 0.59.

### Что было сделано:
**1.** На первом шаге мы подготовили наши данные для дальнейших исследований: 
 • Обработали дубликаты
 • Обработали пропуски
 • Произвели кодировку признаков
 • Разделили данные на обучающую, валидационную и тестовую выборки.
 • Нормализовали количественные признаки

**2.** На втором шаге мы обучали модель без учета дисбаланса классов.  

Наилучший f1-score, равный 0.53 мы получили при гиперпараметрах модели случайного леса 'max_depth'= 11, 'n_estimators'= 30.  
После построения ROC-кривой мы посчитали AUC ROC score: 0.86.

Поскольку нам нужно было довести метрику F1 до 0.59, мы перешли к различным способам борьбы с дисбалансом.

**3.** При борьбе с дисбалансом мы:  
​
1. Оценивали работу моделей Случайного леса, Дерева решений и Логистической регрессии.  
2. Сначала мы придали классам одинаковый вес. Лучший F1-score стал: 0.63   
3. После провели downsampling нулевого класса. Лучший F1-score на данном этапе был: 0.59   
4. Далее изменяли размер классов с помощью upsampling-а. Лучший F1-score: 0.64  
5. В конце мы попробовали изменить вероятностный порог предсказания класса. F1-score не изменился.  

**4.** На последнем шаге мы провели тестирование лучшей модели:  

Модель Случайного леса с 170  предскзателями и глубиной 11, при использовании upsampling-а классов получила F1-score = 0.60.  
Для оценки адекватности модели мы сравнивали её с dummy-моделью, которая имела F1-score = 0.34.