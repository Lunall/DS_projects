# Проект 12. Классификация комментариев c BERT

### Вводная 
Интернет магазин Bombastic Games начал успешно продавать игры и у них на сайте стало появляться большое количество отзывов. Как хороших, так и негативных. В ручную проверять все отзывы уже не получается, и магазин хочет создать инструмент, позволяющий определять негативные и токсичные комментарии автоматически. 
    
Вам необходимо разработать модель, которая будет автоматически классифицировать комментарии на позитивные и негативные. Для этого вам предоставили набор данных с разметкой о токсичности комментариев.
    
Руководство хочет получить модель со значением метрики качества *F1* не меньше 0.75. 

### Цель проекта 
​	Обучить модель разделять комментарии на позитивные и негативные, её *F1* должен быть не меньше 0.75. 

### Что было сделано:
**1.** На первом шаге мы подготовили наши данные для дальней работы. 
1. Загрузили данные. Всего для анализа было получено 159571 комментариев и их тональности.
2. Проверили дубликаты и пропуски.
3. Произвели лемматизацию текста с помощью Wordnet Lemmatizer (с тэггером части речи POS).
4. Векторизовали тексты через TF-IDF для N-грамм слов.
5. Создали эмбеддинги с помощью DistilBERT. Для анализа мы взяли 500 случайных комментариев. Отметим, что для создания эмбеддингов для 500 текстов нам потребовалось 3 минуты. Мы оценили что вычислительная сложность модели как минимум квадратичная.

**2.** На втором этапе мы проанализировали наши данные.
- Проверили распределение целевого признака, 
- уточнили задачу обучения – бинарная классификация, 
- а также создали переменную для придания веса классам в целевом признаке.

**3.** Третий этап был посвящен обучению моделей и их оценке.

В начале вы выбрали метрику для оценки качества моделей. Для оценки моделей на этапе обучения было решено использовать метрику F1. 
Далее мы разделили выборки на тестовую и обучающую случайным образом, в соотношении 4:1.

3.1. `LogisticRegression`  
При обучении и подборе гиперпарметров мы использовали кросс-валидацию и следующие гиперпараметры: вес классов - сбалансированный, сила регуляризации от 0.0001 до 10.  
Средний F1 на обучающей выборке был равен 0.758, это уже позволило достичь минимально требуемого значения в 0.75.

3.2.` RandomForestClassifier`  
Было обнаружено, что в данной задаче модель случайного леса работает гораздо медленней логистической регрессии и показывает низкие результаты (лучший средний F1: 0.42). Скорее всего это связано с тем, что признаков очень много (161394), и для хорошего предсказания необходимо строить очень глубокие деревья. Однако это будет занимать очень много времени и вычислительных ресурсов.

3.3.  `XGBoost`  
В данном проекте мы использовали XGBoost sklearn API. Гиперпараметры к XGB было решено подбирать с помощью кривых обучения. Они позволяли оценить как влияет количество деревьев на качество предсказания, в зависимости от величины шага градиентного спуска (learning rate). Для перебора lr и использовали логарифмическое пространство от 0.05 до 1.
На первой итерации мы получили лучший средний F1: 0.7295. После этого мы зафиксировали lr и построили больше деревьев.  
Мы получили средний F1: 0.747 при 700 деревьев, было решено остановиться на нём, однако можно было увеличивать learnning rate и ещё улучшить результат.

3.4. `Модель Логистической регрессии на эмбеддингах BERT`  
Лучший F1 на валидационной выборке = 0.4615, при С = 5.26. Результат далек от F1 > 0.75. По всей видимости логистической регрессии не хватает данных для обучения – у нас длинна 1 комментария может достигать до 512 токенов, а обучающая выборка состоит из всего 300 элементов.

Если нам необходимо будет проверять сообщения в реальном времени, то пропускной способности обрабатывать 500 текстов за 3 минуты может быть не достаточно. Поскольку сложность у нас как минимум квадратичная, то при увеличении количества текстов, время будет увеличиваться в квадрате. В этом случае рекомендуется использовать более легкую модель – Логистическую регрессию на TF-IDF векторах.


Таблица результатов:

| Модель                      | F1 score | Время предсказания |
| :-------------------------- | -------- | ------------------ |
| **Логистическая регрессия** | 0.755    | 9 s                |
| **Случайный лес**           | 0.44     | 19 s               |
| **XGBoost**                 | 0.748    | 2 min              |
| **BERT + Лог. регрессия**   | 0.545    | 3 min              |

3.5. Далее мы проверили лучшую модель на тестовой выборке.  
F1-score модели логистической регрессии на TF-IDF векторах на тестовой выборке = 0.7547.

3.6. В конце была проведена проверка моделей на адекватность.  
Итоговый F1 dummy модели, не использующей машинное обучение, составила  0.105. Как видим, наши модели построены не зря – они имеют большую точность (до 0.755).
